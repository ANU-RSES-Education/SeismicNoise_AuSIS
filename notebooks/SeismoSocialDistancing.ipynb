{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Motion Displacement RMS vs Time\n",
    "\n",
    "*an example simple tutorial for getting seismic data, computing the power spectral densities, extracting the RMS and plotting*\n",
    "\n",
    "Required:\n",
    "\n",
    "- python\n",
    "- obspy (and its dependencies)\n",
    "- pandas\n",
    "- jupyter\n",
    "- notebook\n",
    "- tqdm\n",
    "\n",
    "this should be easy to set up in a conda env: ``conda create -c conda-forge -n covid python=3.7 obspy pandas jupyter notebook tqdm``\n",
    "\n",
    "Author: Thomas Lecocq @seismotom, Fred Massin @fmassin, Claudio Satriano @claudiodsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42  # to edit text in Illustrator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "from obspy import UTCDateTime, read\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.client import FDSNNoDataException\n",
    "from obspy.signal import PPSD\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seismosocialdistancing_core as seismosocialdistancing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Start/End dates and Seismic Channel\n",
    "\n",
    "You'll have to make sure the seed_id you request is indeed available from the ``data_provider``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The station information is provided in a file called `seismosocialdistancing_settings.py \n",
    "\n",
    "import seismosocialdistancing_settings as ssd\n",
    "\n",
    "start = ssd.start\n",
    "end = ssd.end\n",
    "safety_window = ssd.safety_window\n",
    "\n",
    "network   = ssd.network\n",
    "station   = ssd.station\n",
    "location  = ssd.location\n",
    "channel   = ssd.channel\n",
    "dataset   = ssd.dataset\n",
    "time_zone = ssd.time_zone\n",
    "sitedesc  = ssd.sitedesc\n",
    "\n",
    "reference_period=ssd.reference\n",
    "lockdown_period=ssd.lockdown\n",
    "reopening_date=ssd.reopening\n",
    "holiday_period=ssd.summer_hol\n",
    "\n",
    "data_provider = ssd.data_provider\n",
    "logo = ssd.logo\n",
    "bans = ssd.bans\n",
    "\n",
    "datelist = pd.date_range(start.datetime, min(end, UTCDateTime()).datetime, freq=\"D\")\n",
    "\n",
    "# This is the current date in pandas format\n",
    "today = pd.to_datetime(UTCDateTime.now().date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download the seismic waveform data\n",
    "\n",
    "This step is coded so that only the last day is redownloaded if the daily files are present on the disk.\n",
    "\n",
    "The request gets the target day +- 30 minutes to avoid having gaps at the end of each day (need 1 window covering midnight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-02-09_S1.AUKSC..BHZ.mseed:  30%|██▉       | 58/195 [00:00<00:00, 471.96it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-01-27_S1.AUKSC..BHZ.mseed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-04-18_S1.AUKSC..BHZ.mseed:  71%|███████▏  | 139/195 [00:00<00:00, 158.25it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-02-09_S1.AUKSC..BHZ.mseed\n",
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-04-17_S1.AUKSC..BHZ.mseed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-05-06_S1.AUKSC..BHZ.mseed:  71%|███████▏  | 139/195 [00:00<00:00, 158.25it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-04-18_S1.AUKSC..BHZ.mseed\n",
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-04-19_S1.AUKSC..BHZ.mseed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-06-05_S1.AUKSC..BHZ.mseed:  82%|████████▏ | 159/195 [00:01<00:00, 104.74it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-05-06_S1.AUKSC..BHZ.mseed\n",
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-05-07_S1.AUKSC..BHZ.mseed\n",
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-06-04_S1.AUKSC..BHZ.mseed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-06-07_S1.AUKSC..BHZ.mseed:  96%|█████████▋| 188/195 [00:01<00:00, 120.50it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-06-05_S1.AUKSC..BHZ.mseed\n",
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-06-06_S1.AUKSC..BHZ.mseed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-06-11_S1.AUKSC..BHZ.mseed:  96%|█████████▋| 188/195 [00:01<00:00, 120.50it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-06-07_S1.AUKSC..BHZ.mseed\n",
      "No data on FDSN server for ../workdir/Australia_AUKSC_2020-06-08_S1.AUKSC..BHZ.mseed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching    - ../workdir/Australia_AUKSC_2020-06-11_S1.AUKSC..BHZ.mseed:  99%|█████████▉| 193/195 [00:04<00:00, 44.82it/s] \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../workdir/Australia_AUKSC_2020-06-11_S1.AUKSC..BHZ.mseed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b108561442a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data on FDSN server for %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# This is to ensure that we get recent information but allow fallback to earlier dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/covid/lib/python3.7/site-packages/obspy/core/stream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, format, **kwargs)\u001b[0m\n\u001b[1;32m   1460\u001b[0m             raise ValueError(msg % (format,\n\u001b[1;32m   1461\u001b[0m                                     ', '.join(ENTRY_POINTS['waveform_write'])))\n\u001b[0;32m-> 1462\u001b[0;31m         \u001b[0mwrite_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def trim(self, starttime=None, endtime=None, pad=False,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/covid/lib/python3.7/site-packages/obspy/io/mseed/core.py\u001b[0m in \u001b[0;36m_write_mseed\u001b[0;34m(stream, filename, encoding, reclen, byteorder, sequence_number, flush, verbose, **_kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;31m# Open filehandler or use an existing file like object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../workdir/Australia_AUKSC_2020-06-11_S1.AUKSC..BHZ.mseed'"
     ]
    }
   ],
   "source": [
    "force_reprocess = False\n",
    "\n",
    "import pathlib\n",
    "pathlib.Path(os.path.join(\"..\",\"data\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "c = Client(data_provider, timeout=10.0)\n",
    "\n",
    "nslc = \"{}.{}.{}.{}\".format(network, station, location, channel)\n",
    "# make sure that wildcard characters are not in nslc\n",
    "nslc = nslc.replace(\"*\", \"\").replace(\"?\", \"\")\n",
    "pbar = tqdm.tqdm(datelist)\n",
    "goodday=None\n",
    "\n",
    "for day in pbar:\n",
    "    datestr = day.strftime(\"%Y-%m-%d\")\n",
    "    fn  = os.path.join(\"..\",\"workdir\",\"{}_{}_{}.mseed\".format(dataset, datestr, nslc))\n",
    "    fnz = os.path.join(\"..\",\"data\",\"{}_{}_{}.npz\".format(dataset, datestr, nslc))\n",
    "    \n",
    "    if (today-day > safety_window) and (os.path.isfile(fn) or (os.path.isfile(fnz) and not force_reprocess)):\n",
    "        pbar.set_description(\"Using cache - %s\" % fn)\n",
    "        goodday = day\n",
    "        continue\n",
    "    else:\n",
    "        pbar.set_description(\"Fetching    - %s\" % fn)\n",
    "        try: \n",
    "            st = c.get_waveforms(network, station, location, channel,\n",
    "                                  UTCDateTime(day)-1801, UTCDateTime(day)+86400+1801,\n",
    "                                  attach_response=True)\n",
    "            goodday=day\n",
    "        except FDSNNoDataException:\n",
    "            print(\"No data on FDSN server for %s\" % fn)\n",
    "            pbar.set_description(\"No data on FDSN server for %s\" % fn)\n",
    "            continue\n",
    "        st.write(fn)\n",
    "\n",
    "# This is to ensure that we get recent information but allow fallback to earlier dates \n",
    "\n",
    "for day in datelist[::-1]:  \n",
    "    try:\n",
    "        resp = c.get_stations(UTCDateTime(day), network=network, station=station, location=location,\n",
    "                      channel=channel, level=\"response\")\n",
    "        print(\"Response for date: {}\".format(day))\n",
    "        print(resp)\n",
    "        break\n",
    "    except:\n",
    "        print(\"Exception for date: {}\".format(day))\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = c.get_waveforms(network, station, location, channel,\n",
    "                                  UTCDateTime(goodday)-1801, UTCDateTime(goodday)+86400+1801,\n",
    "                                  attach_response=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute PPSDs using custom parameters\n",
    "\n",
    "These parameters are set to allow the PSDs to be \"nervous\", not as smooth as the default PQLX ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "pbar = tqdm.tqdm(datelist)\n",
    "for day in pbar:\n",
    "    datestr = day.strftime(\"%Y-%m-%d\")\n",
    "    fn_in = os.path.join(\"..\",\"workdir\",\"{}_{}_{}.mseed\".format(dataset, datestr, nslc))\n",
    "    pbar.set_description(\"Processing %s\" % fn_in)\n",
    "    if not os.path.isfile(fn_in):\n",
    "        continue\n",
    "    stall = read(fn_in, headonly=True)\n",
    "    for mseedid in list(set([tr.id for tr in stall])):\n",
    "        fn_out = os.path.join(\"..\",\"data\",\"{}_{}_{}.npz\".format(dataset, datestr, mseedid))\n",
    "        if (today-day > safety_window) and (os.path.isfile(fn_out) and not force_reprocess):\n",
    "            continue\n",
    "        st = read(fn_in, sourcename=mseedid)\n",
    "        st.attach_response(resp)\n",
    "        ppsd = PPSD(st[0].stats, metadata=resp,\n",
    "                    ppsd_length=1800, overlap=0.5,\n",
    "                    period_smoothing_width_octaves=0.025,\n",
    "                    period_step_octaves=0.0125,\n",
    "                    period_limits=(0.008, 50),\n",
    "                    db_bins=(-200, 20, 0.25))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            ppsd.add(st)\n",
    "        ppsd.save_npz(fn_out[:-4])\n",
    "        del st, ppsd\n",
    "    del stall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Reload daily PSDs from the disk and create a single PPSD object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppsds = {}\n",
    "pbar = tqdm.tqdm(datelist)\n",
    "for day in pbar:\n",
    "    datestr = day.strftime(\"%Y-%m-%d\")\n",
    "    fn_pattern = os.path.join(\"..\",\"data\",\"{}_{}_*.npz\".format(dataset, datestr))\n",
    "    pbar.set_description(\"Reading %s\" % fn_pattern)\n",
    "    for fn in glob(fn_pattern):\n",
    "        mseedid = fn.replace(\".npz\", \"\").split(\"_\")[-1]\n",
    "        if mseedid not in ppsds:\n",
    "            ppsds[mseedid] = PPSD.load_npz(fn)#, allow_pickle=True)\n",
    "        else:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                ppsds[mseedid].add_npz(fn)#, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Standard plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ppsd.plot(max_percentage=10) for mseedid, ppsd in ppsds.items()]\n",
    "[ppsd.plot_temporal(0.10) for mseedid, ppsd in ppsds.items()]\n",
    "[ppsd.plot_spectrogram(clim=(-160,-100)) for mseedid, ppsd in ppsds.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Process PSDs to extract the RMS(displacement)\n",
    "\n",
    "This can be done for multiple filters at once (``freqs`` below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define frequency bands of interest:\n",
    "freqs = [(0.1,1.0),(1.0,20.0),(4.0,14.0),(4.0,20.0)]\n",
    "\n",
    "displacement_RMS = {}\n",
    "for mseedid, ppsd in tqdm.tqdm(ppsds.items()):\n",
    "    ind_times = pd.DatetimeIndex([d.datetime for d in ppsd.current_times_used])\n",
    "    data = pd.DataFrame(ppsd.psd_values, index=ind_times, columns=1./ppsd.period_bin_centers)\n",
    "    data = data.sort_index(axis=1)\n",
    "    displacement_RMS[mseedid] = seismosocialdistancing.df_rms(data, freqs, output=\"DISP\")\n",
    "    # displacement_RMS[mseedid].to_csv(os.path.join(\"..\", \"results\", \"%s.csv\" % mseedid))\n",
    "    displacement_RMS[mseedid].to_csv(os.path.join(\"..\", \"results\", \"latest.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekday / Time of day Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'band':\"4.0-14.0\",       # might be None or commented (\"4.0-14.0\" per default) or any of the tupples in freqs\n",
    "        'time_zone':time_zone,   # required for clockplots\n",
    "        'sitedesc':sitedesc,     # might be None or commented\n",
    "        'logo':logo,             # might be None or commented\n",
    "        'bans':bans,             # might be None or commented\n",
    "        'save':'../results/',    # might be None or commented or a path \n",
    "        'unit':'nm',\n",
    "        'format':'png',\n",
    "        'show':True,\n",
    "        'basename':\"../results/latest\",      # to over-ride the default name\n",
    "        'reference_period':reference_period,\n",
    "        'lockdown_period':lockdown_period,\n",
    "        'reopening_date':reopening_date,\n",
    "        'holiday_period':holiday_period\n",
    "       }\n",
    "\n",
    "seismosocialdistancing.plot(displacement_RMS,\n",
    "                            type='timeseries',\n",
    "                            **args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seismosocialdistancing.plot(displacement_RMS,\n",
    "#                             type='dailyplots',\n",
    "#                             **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismosocialdistancing_core as seismosocialdistancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismosocialdistancing.plot(displacement_RMS,\n",
    "                            type='sclockplots',\n",
    "                            **args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise distribution over time of the day  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seismosocialdistancing.plot(displacement_RMS,\n",
    "#                             type='clockmaps',\n",
    "#                             **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismosocialdistancing.plot(displacement_RMS,\n",
    "                            type='gridmaps',\n",
    "                            **args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary code: All your stations' colormapped plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "normalize = True\n",
    "resample_freq = \"1H\"\n",
    "clip = (0.05,0.95)\n",
    "\n",
    "#concatenating in a single dataframe and converting to nm\n",
    "dRMS2D = pd.concat(displacement_RMS, axis=0) * 1e9\n",
    "for band in dRMS2D.columns:\n",
    "    g = dRMS2D.loc[:,band].unstack().T\n",
    "    g = g.clip(g.quantile(clip[0]),g.quantile(clip[1]),axis=1)\n",
    "    g = g.resample(resample_freq).median()\n",
    "    if normalize:\n",
    "        g -= g.quantile(0.01)\n",
    "        g /= g.quantile(0.99)\n",
    "        vmin, vmax = 0, 1\n",
    "    else:\n",
    "        vmin = vmax = None\n",
    "   \n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,2*len(g.columns)))\n",
    "    label = '%sDisplacement (µm)' % [\"\",\"Normalized \"][normalize]\n",
    "\n",
    "    x = np.append(g.index.values, g.index.shift(1).values[-1])\n",
    "    y = np.append(g.columns, \"\")\n",
    "    plt.pcolormesh(x, y, g.T,  cmap=\"inferno\", vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(orientation='horizontal', shrink=0.3).set_label(label)\n",
    "    pos, l = plt.yticks()\n",
    "    plt.yticks(np.asarray(pos)+0.5, y)\n",
    "    plt.margins(0)\n",
    "    plt.title(\"%s Hz\" % band)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}